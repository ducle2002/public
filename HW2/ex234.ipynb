{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e8SpNjvYBZ9o",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:34:47.037932Z",
     "start_time": "2024-04-21T17:34:47.033932Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import urllib\n",
    "from skimage.transform import resize\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "from IPython.display import display\n",
    "from skimage import io as io_url\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BEZerYH0A49C",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:34:47.136490Z",
     "start_time": "2024-04-21T17:34:47.038932Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1), <c16",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Study\\xu li anh\\HW2\\HW2\\venv\\Lib\\site-packages\\PIL\\Image.py:3130\u001B[0m, in \u001B[0;36mfromarray\u001B[1;34m(obj, mode)\u001B[0m\n\u001B[0;32m   3129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3130\u001B[0m     mode, rawmode \u001B[38;5;241m=\u001B[39m \u001B[43m_fromarray_typemap\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtypekey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   3131\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyError\u001B[0m: ((1, 1), '<c16')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 65\u001B[0m\n\u001B[0;32m     62\u001B[0m slider_inner\u001B[38;5;241m.\u001B[39mobserve(on_value_change3, names\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     63\u001B[0m slider_outer\u001B[38;5;241m.\u001B[39mobserve(on_value_change3, names\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 65\u001B[0m \u001B[43mon_value_change3\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m display(sidebyside)\n\u001B[0;32m     68\u001B[0m display(slider_inner)\n",
      "Cell \u001B[1;32mIn[9], line 56\u001B[0m, in \u001B[0;36mon_value_change3\u001B[1;34m(change)\u001B[0m\n\u001B[0;32m     53\u001B[0m image3_spatial\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m=\u001B[39m buf\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[0;32m     55\u001B[0m buf\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 56\u001B[0m tmp \u001B[38;5;241m=\u001B[39m \u001B[43mPIL\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m255\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.0001\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfimg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m tmp \u001B[38;5;241m=\u001B[39m tmp\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     58\u001B[0m tmp\u001B[38;5;241m.\u001B[39msave(buf, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpng\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mD:\\Study\\xu li anh\\HW2\\HW2\\venv\\Lib\\site-packages\\PIL\\Image.py:3134\u001B[0m, in \u001B[0;36mfromarray\u001B[1;34m(obj, mode)\u001B[0m\n\u001B[0;32m   3132\u001B[0m         typekey_shape, typestr \u001B[38;5;241m=\u001B[39m typekey\n\u001B[0;32m   3133\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot handle this data type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtypekey_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtypestr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 3134\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m   3135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3136\u001B[0m     rawmode \u001B[38;5;241m=\u001B[39m mode\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot handle this data type: (1, 1), <c16"
     ]
    }
   ],
   "source": [
    "# Create image widgets\n",
    "image3_spatial = widgets.Image(format='png', width=500, height=500, description='Spatial')\n",
    "image3_freq    = widgets.Image(format='png', width=500, height=500, description='Frequency')\n",
    "sidebyside     = widgets.HBox([image3_spatial, image3_freq])\n",
    "\n",
    "# Create slider/select widgets\n",
    "slider_inner   = widgets.FloatSlider(value=0,      min=0, max=1,      step=0.01, description='Inner radius')\n",
    "slider_outer   = widgets.FloatSlider(value=1.44/2, min=0, max=1.44/2, step=0.01, description='Outer radius')\n",
    "\n",
    "buf            = io.BytesIO()\n",
    "\n",
    "orig_img = io_url.imread('https://img2.zergnet.com/2309662_300.jpg')\n",
    "orig_img = np.mean(orig_img, -1)\n",
    "\n",
    "x = np.fft.fftfreq(orig_img.shape[0]);\n",
    "y = np.fft.fftfreq(orig_img.shape[1]);\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xv = np.fft.fftshift(xv)\n",
    "yv = np.fft.fftshift(yv)\n",
    "\n",
    "def filter_frequency(orig_img, mask):\n",
    "    \"\"\"\n",
    "    Remove frequency based on the given mask.\n",
    "    Params:\n",
    "        orig_img: numpy image\n",
    "        mask: same shape with orig_img indicating which frequency to hold or remove\n",
    "    Output:\n",
    "        f_img: frequency image after applying mask\n",
    "        img: image after applying mask\n",
    "    \"\"\"\n",
    "    # Compute the 2D Fourier transform of the input image\n",
    "    f_img = np.fft.fft2(orig_img)\n",
    "    \n",
    "    # Apply the mask to the Fourier transform\n",
    "    f_img_filtered = f_img * mask\n",
    "    \n",
    "    # Compute the inverse Fourier transform to obtain the filtered image\n",
    "    img = np.fft.ifft2(f_img_filtered).real\n",
    "    \n",
    "    return f_img_filtered, img\n",
    "\n",
    "def on_value_change3(change):\n",
    "    mask = (np.sqrt(xv**2 + yv**2) < slider_outer.value) & \\\n",
    "           (np.sqrt(xv**2 + yv**2) >= slider_inner.value)\n",
    "    mask = np.float32(mask)\n",
    "\n",
    "    fimg, img = filter_frequency(orig_img, mask)\n",
    "    buf.seek(0)\n",
    "    tmp = PIL.Image.fromarray(255*img/(img.max()+0.0001))\n",
    "    tmp = tmp.convert('L')\n",
    "    tmp.save(buf, 'png')\n",
    "    image3_spatial.value = buf.getvalue()\n",
    "\n",
    "    buf.seek(0)\n",
    "    tmp = PIL.Image.fromarray(255*np.log(0.0001*fimg + 1))\n",
    "    tmp = tmp.convert('L')\n",
    "    tmp.save(buf, 'png')\n",
    "    image3_freq.value = buf.getvalue()\n",
    "\n",
    "\n",
    "slider_inner.observe(on_value_change3, names='value')\n",
    "slider_outer.observe(on_value_change3, names='value')\n",
    "\n",
    "on_value_change3(0)\n",
    "\n",
    "display(sidebyside)\n",
    "display(slider_inner)\n",
    "display(slider_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVrTefqfDt4S",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:34:47.136998Z",
     "start_time": "2024-04-21T17:34:47.136998Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_img(img_path, img_size=(512, 512)):\n",
    "  \"\"\"\n",
    "    + Đọc ảnh\n",
    "    + Chuyển thành grayscale\n",
    "    + Thay đổi kích thước ảnh thành img_size\n",
    "  \"\"\"\n",
    "  img = cv2.imread(img_path, 0)\n",
    "  img = cv2.resize(img, img_size)\n",
    "  return img\n",
    "\n",
    "\n",
    "def create_hybrid_img(img1, img2, r):\n",
    "    \"\"\"\n",
    "    Create hybrid image\n",
    "    Params:\n",
    "        img1: numpy image 1\n",
    "        img2: numpy image 2\n",
    "        r: radius that defines the filled circle of frequency of image 1.\n",
    "           This radius determines which frequency components are preserved from img1.\n",
    "    \"\"\"\n",
    "    # Compute the Fourier transform of both images\n",
    "    f_img1 = np.fft.fft2(img1)\n",
    "    f_img2 = np.fft.fft2(img2)\n",
    "    \n",
    "    # Create a circular mask to preserve low frequencies in img1\n",
    "    x, y = img1.shape\n",
    "    xv, yv = np.meshgrid(np.arange(y), np.arange(x))\n",
    "    center_x, center_y = x // 2, y // 2\n",
    "    mask = np.sqrt((xv - center_x) ** 2 + (yv - center_y) ** 2) < r * min(center_x, center_y)\n",
    "    \n",
    "    # Apply the mask to img1's Fourier transform and (1 - mask) to img2's Fourier transform\n",
    "    f_img1_low = f_img1 * mask\n",
    "    f_img2_high = f_img2 * (1 - mask)\n",
    "    \n",
    "    # Combine the low-frequency components of img1 with the high-frequency components of img2\n",
    "    f_hybrid = f_img1_low + f_img2_high\n",
    "    \n",
    "    # Compute the inverse Fourier transform to obtain the hybrid image\n",
    "    hybrid_img = np.fft.ifft2(f_hybrid).real\n",
    "    \n",
    "    return hybrid_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uB8hOFkPDxzS",
    "ExecuteTime": {
     "end_time": "2024-04-21T17:34:54.042464Z",
     "start_time": "2024-04-21T17:34:54.024672Z"
    }
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m image_1_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;66;03m# <-- need to change\u001B[39;00m\n\u001B[0;32m      2\u001B[0m image_2_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;66;03m# <-- need to change\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m img_1 \u001B[38;5;241m=\u001B[39m \u001B[43mread_img\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_1_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m img_2 \u001B[38;5;241m=\u001B[39m read_img(image_2_path)\n\u001B[0;32m      5\u001B[0m hybrid_img \u001B[38;5;241m=\u001B[39m create_hybrid_img(img_2, img_1, \u001B[38;5;241m14\u001B[39m)\n",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m, in \u001B[0;36mread_img\u001B[1;34m(img_path, img_size)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m  + Đọc ảnh\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m  + Chuyển thành grayscale\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m  + Thay đổi kích thước ảnh thành img_size\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      7\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(img_path, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "image_1_path = \"\" # <-- need to change\n",
    "image_2_path = \"\" # <-- need to change\n",
    "img_1 = read_img(image_1_path)\n",
    "img_2 = read_img(image_2_path)\n",
    "hybrid_img = create_hybrid_img(img_2, img_1, 14)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 15))\n",
    "axes[0].imshow(img_1, cmap=\"gray\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(img_2, cmap=\"gray\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(hybrid_img, cmap=\"gray\")\n",
    "axes[2].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
